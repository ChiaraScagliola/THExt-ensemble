{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7rnm0L_Zblp"
      },
      "source": [
        "# Task 1 ( Fine-Tuning CNN Dailymail Dataset )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJ2EeuYyZuy6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QuBUZwuZy4b"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/THExt-ensemble-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPDqwEBJobVl"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "metadata": {
        "id": "a-YBzDvxuQh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xtlGAr5pZs6n"
      },
      "outputs": [],
      "source": [
        "from finetuning import finetuning\n",
        "import pandas as pd\n",
        "import rouge\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from Thext import SentenceRankerPlus\n",
        "from Thext import Highlighter\n",
        "from Thext import RedundancyManager\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finetuning(\"dataset_fine_tuning_THExt.csv\", \"checkpoint\")"
      ],
      "metadata": {
        "id": "4WFd1EWo5lve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CT8PCfEIDSZ"
      },
      "source": [
        "Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dd_-B9iaIE5R"
      },
      "outputs": [],
      "source": [
        "def evaluate(text, hs,  sentences):\n",
        "\n",
        "    predicted_highlights_concat = ' '.join(map(str, sentences))\n",
        "    real_highlights_concat =  hs\n",
        "\n",
        "    r_computer = rouge.Rouge(metrics=['rouge-n', 'rouge-l'], limit_length=False, max_n=2, alpha=0.5, stemming=False)\n",
        "    score = r_computer.get_scores(predicted_highlights_concat,real_highlights_concat) \n",
        "\n",
        "    return score['rouge-1']['f'],score['rouge-2']['f'], score['rouge-l']['f']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZNQi2XkcCqR"
      },
      "outputs": [],
      "source": [
        "data = load_dataset(\"cnn_dailymail\" ,\"3.0.0\", split=\"validation\")\n",
        "data = pd.DataFrame(data).iloc[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KyTUY934bvFb"
      },
      "outputs": [],
      "source": [
        "model_name_or_path='checkpoint' \n",
        "base_model_name = \"morenolq/thext-cs-scibert\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlqLTuwTaibN"
      },
      "outputs": [],
      "source": [
        "sr = SentenceRankerPlus(device='cuda')\n",
        "sr.load_model(base_model_name=base_model_name, model_name_or_path=model_name_or_path,device='cuda')\n",
        "rm = RedundancyManager()\n",
        "h = Highlighter(sr, redundancy_manager = rm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "A-PlhWqkbydm"
      },
      "outputs": [],
      "source": [
        "r1_f = np.array([])\n",
        "r2_f = np.array([])\n",
        "rl_f = np.array([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VINOlLVob81_"
      },
      "outputs": [],
      "source": [
        "for i in range(len(data)):\n",
        "  text = data.iloc[i]['article']\n",
        "  highlights = data.iloc[i]['highlights']\n",
        "\n",
        "  sum = h.get_highlights_simple(text, abstract = True, rel_w=1.0, pos_w=0.0, red_w=0.0, prefilter=False, NH = 3)\n",
        "\n",
        "\n",
        "  r1f,r2f,rlf = evaluate(text, highlights, sentences = sum)\n",
        "\n",
        "  r1_f = np.append(r1_f,r1f)\n",
        "  r2_f = np.append(r2_f,r2f)\n",
        "  rl_f = np.append(rl_f,rlf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgNR_pzFIX2Q"
      },
      "outputs": [],
      "source": [
        "print(f\"Avarage Rougue-1 f1 score : { np.average(r1_f) }\")\n",
        "print(f\"Avarage Rougue-2 f1 score : { np.average(r2_f) }\")\n",
        "print(f\"Avarage Rougue-l f1 score : { np.average(rl_f) }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOXf2gbvsg20"
      },
      "source": [
        "# Task 2 ( Ensamble method )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7dEV05rqJvR1"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from utils import Ensemble\n",
        "from datasets import load_dataset\n",
        "import rouge\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRk7e8aEF5m6"
      },
      "source": [
        "Fit models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX5PkKWFCeYb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "random_ensamble = Ensemble(\"RandomForest\")\n",
        "sgd_ensamble = Ensemble(\"sgd\")\n",
        "lasso_ensamble = Ensemble(model = LassoCV(cv=5, random_state=0))\n",
        "\n",
        "data = pd.read_csv(\"data_train.csv\") #specificare nel readme di scaricare il dataset dal drive e metterlo nella cartella\n",
        "\n",
        "X = data[['text_rank', 'lsa_score', 'tf_idf', 'relevance_score', 'thext_score', 'pos_i']]\n",
        "y = data['rouge_2f']\n",
        "\n",
        "random_ensamble.train(X,y)\n",
        "sgd_ensamble.train(X,y)\n",
        "lasso_ensamble.train(X,y)\n",
        "\n",
        "random_ensamble.save(\"random\")\n",
        "sgd_ensamble.save(\"sgd\")\n",
        "lasso_ensamble.save(\"lasso\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MFtYMCpIDO8"
      },
      "source": [
        "Test models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "r6T5qRcLDD0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2106a749-6c2f-46d7-eac4-917ac8706b2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/1b3c71476f6d152c31c1730e83ccb08bcf23e348233f4fcc11e182248e6bf7de)\n"
          ]
        }
      ],
      "source": [
        "#random_ensamble.load(\"random\")\n",
        "#sgd_ensamble.load(\"sgd\")\n",
        "#lasso_ensamble.load(\"lasso\")\n",
        "\n",
        "data = load_dataset(\"cnn_dailymail\" ,\"3.0.0\", split=\"validation\")\n",
        "data = pd.DataFrame(data).iloc[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "x0zKqCSjLjPq"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, data):\n",
        "\tr1_f = []\n",
        "\tr2_f = []\n",
        "\trl_f = []\n",
        "\tfor i in range(len(data)):\n",
        "\t\ttext = data.iloc[i]['article']\n",
        "\t\thighlights = data.iloc[i]['highlights']\n",
        "\t\tr1f,r2f,rlf = model.evaluate(text, highlights)\n",
        "\t\tr1_f.append(r1f)\n",
        "\t\tr2_f.append(r2f)\n",
        "\t\trl_f.append(rlf)\n",
        "\tprint(f\"Avarage Rougue-1 f1 score : { np.average(r1_f) }\")\n",
        "\tprint(f\"Avarage Rougue-2 f1 score : { np.average(r2_f) }\")\n",
        "\tprint(f\"Avarage Rougue-l f1 score : { np.average(rl_f) }\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA9gGQNVIofG"
      },
      "outputs": [],
      "source": [
        "evaluate(random_ensamble, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cs3H-a4lOuk-"
      },
      "outputs": [],
      "source": [
        "evaluate(sgd_ensamble, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFJ4WXI0PS2w"
      },
      "outputs": [],
      "source": [
        "evaluate(lasso_ensamble, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWbfZkSTPeVc"
      },
      "source": [
        "Independent set method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFfrWtCBPzNk"
      },
      "outputs": [],
      "source": [
        "from utils import RedundancyIndipendentSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jA-2wakTGeY"
      },
      "outputs": [],
      "source": [
        "random_ensamble.load(\"random\")\n",
        "\n",
        "data = load_dataset(\"cnn_dailymail\" ,\"3.0.0\", split=\"validation\")\n",
        "data = pd.DataFrame(data).iloc[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSO8zgiQaLva"
      },
      "outputs": [],
      "source": [
        "r = RedundancyIndipendentSet()\n",
        "\n",
        "r1_f = np.array([])\n",
        "r2_f = np.array([])\n",
        "rl_f = np.array([])\n",
        "r1_f_ind = np.array([])\n",
        "r2_f_ind = np.array([])\n",
        "rl_f_ind = np.array([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbJdfc6eaGpv"
      },
      "outputs": [],
      "source": [
        "for i in range(len(data)):\n",
        "\n",
        "  text = data.iloc[i]['article']\n",
        "  highlights = data.iloc[i]['highlights']\n",
        "\n",
        "  sum = random_ensamble.summary(text, NH = 3)\n",
        "  sum_redundancy = random_ensamble.summary(text, NH = 5, score=True)\n",
        "  ind = r.indipendent_set(sum_redundancy)\n",
        "\n",
        "  r1f_ind,r2f_ind,rlf_ind = random_ensamble.evaluate(text, highlights, sent = ind )\n",
        "  r1f,r2f,rlf = random_ensamble.evaluate(text, highlights, sent = sum)\n",
        "\n",
        "  r1_f = np.append(r1_f,r1f)\n",
        "  r2_f = np.append(r2_f,r2f)\n",
        "  rl_f = np.append(rl_f,rlf)\n",
        "  r1_f_ind = np.append(r1_f_ind,r1f_ind)\n",
        "  r2_f_ind = np.append(r2_f_ind,r2f_ind)\n",
        "  rl_f_ind = np.append(rl_f_ind,rlf_ind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGeWexQIQaQM"
      },
      "outputs": [],
      "source": [
        "print(f\"\\n\\nAvarage Rougue-1 f1 score : { np.average(r1_f) }\")\n",
        "print(f\"Avarage Rougue-2 f1 score : { np.average(r2_f) }\")\n",
        "print(f\"Avarage Rougue-l f1 score : { np.average(rl_f) }\")\n",
        "print(f\"\\n\\nAvarage Rougue-1 f1 score indipendence method : { np.average(r1_f_ind) }\")\n",
        "print(f\"Avarage Rougue-2 f1 score  indipendence method : { np.average(r2_f_ind) }\")\n",
        "print(f\"Avarage Rougue-l f1 score indipendence method : { np.average(rl_f_ind) }\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}